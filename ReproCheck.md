# ReproCheck


# Reproducibility Check Report

**Title of Repository**:  
\[Repository name with link\]

**Author**:  
\[Name\]

**Date of Check**:  
\[YYYY-MM-DD\]

**Checker**:  
\[Your name\]

------------------------------------------------------------------------

Note: save this qmd in local, complete it and print it as a pdf to
submit it on Canvas.

## 1. Materials and Setup

-   **Repository Access**: Yes or No
-   **Environment Setup**:
    -   OS: \[e.g., Ubuntu 22.04, macOS 14.4\]
    -   Language Version: \[e.g., Python 3.11, R 4.3\]
    -   Key Packages / Tools: \[e.g., pandas, scikit-learn, R
        tidyverse\]
    -   None specified
-   **Installation Issues**:  
    \[Summarize any dependency or setup issues\]

------------------------------------------------------------------------

## 2. Reproduction Attempt

-   **Run Success**: Yes / No (fully) / No (partially)
-   **Steps Followed**:  
    \[e.g., Cloned repo, ran `main.py`, used `data.csv`…\]
-   **Output Comparison**:  
    \[Describe differences/similarities in key outputs or results\]

------------------------------------------------------------------------

## 4. Observations & Issues

-   ☐ Missing files or data
-   ☐ Absolute paths
-   ☐ Unspecified random seed
-   ☐ Incomplete README
-   \[Add other issues here\]

------------------------------------------------------------------------

## 5. Recommendations

-   ☐ Use relative paths
-   ☐ Specify random seed
-   ☐ Improve README with clearer instructions
-   \[Add others as needed\]

------------------------------------------------------------------------

## 6. Summary Rating (submit in Google Sheet)

<table>
<thead>
<tr class="header">
<th>Category</th>
<th>Rating (1–5)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Documentation Quality</td>
<td></td>
</tr>
<tr class="even">
<td>Code Executability</td>
<td></td>
</tr>
<tr class="odd">
<td>Output Reproducibility</td>
<td></td>
</tr>
<tr class="even">
<td>Overall</td>
<td></td>
</tr>
</tbody>
</table>
